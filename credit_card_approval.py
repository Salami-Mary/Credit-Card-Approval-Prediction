# -*- coding: utf-8 -*-
"""Credit Card Approval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jMCdZ0IR-vnAryjMFoXd4O9JC_Iuk0oo
"""

import pandas as pd
# Load dataset
cc_apps = pd.read_csv("/content/drive/MyDrive/Credit card prediction/cc_approvals.data",header=None)
cc_apps.head(5)

cc_apps_description = cc_apps.describe()
print(cc_apps_description)
print("\n")
cc_apps_info = cc_apps.info()
print(cc_apps_info)
print("\n")

import numpy


# Inspect missing values in the dataset
print(cc_apps.tail(17))

# Replace the '?'s with NaN
cc_apps = cc_apps.replace("?","NaN")

# Inspect the missing values again

print(cc_apps)

# Impute the missing values with mean imputation
cc_apps.fillna(cc_apps.mean(), inplace=True)

# Count the number of NaNs in the dataset to verify
print(cc_apps.isnull().sum())

# Impute the missing values with mean imputation
cc_apps.fillna(cc_apps.mean(), inplace=True)

# Count the number of NaNs in the dataset to verify
print(cc_apps.isnull().sum())

"""Preprocessing Data

"""

from sklearn.preprocessing import LabelEncoder
# Instantiate LabelEncoder
le=LabelEncoder()
for col in cc_apps:
    # Compare if the dtype is object
    if cc_apps[col].dtype=='object':
       cc_apps[col]=le.fit_transform(cc_apps[col])

"""Model Training


"""

from sklearn.model_selection import train_test_split
cc_apps = cc_apps.drop([11, 13], axis=1)
cc_apps = cc_apps.to_numpy()
# Segregate features and labels into separate variables
X,y = cc_apps[:,0:13] , cc_apps[:,13]
# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X,
                                y,
                                test_size=0.33,
                                random_state=42)

from sklearn.preprocessing import MinMaxScaler


# Instantiate MinMaxScaler and use it to rescale X_train and X_test

scaler = MinMaxScaler(feature_range=(0, 1))
rescaledX_train = scaler.fit_transform(X_train)
rescaledX_test = scaler.fit_transform(X_test)

from sklearn.linear_model import LogisticRegression


# Instantiate a LogisticRegression classifier with default parameter values
logreg = LogisticRegression()

# Fit logreg to the train set
logreg.fit(rescaledX_train,y_train)

from sklearn.metrics import confusion_matrix
# Using logreg to predict instances from the test set 
y_pred = logreg.predict(rescaledX_test)

# Getting the accuracy score of logreg model and print it
print("Accuracy of logistic regression classifier: ", logreg.score(rescaledX_test,y_test))

# Print the confusion matrix of the logreg model
confusion_matrix(y_test,y_pred)

#the accuracy score of the model is 84% and the number of positve instances predicted is 125 while negtaive response to appoval of cfredit card is 103

from sklearn.metrics import confusion_matrix


# Use logreg to predict instances from the test set and store it
y_pred = logreg.predict(rescaledX_test)
# Get the accuracy score of logreg model and print it
print("Accuracy of logistic regression classifier: ", logreg.score(rescaledX_test,y_test))
# Print the confusion matrix of the logreg model
confusion_matrix(y_test,y_pred)

from sklearn.model_selection import GridSearchCV
tol = [0.1,0.001,0.0001]
max_iter = [100,150,200]
param_grid = dict(tol=tol, max_iter=max_iter)

grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)
# Use scaler to rescale X and assign it to rescaledX
rescaledX = scaler.fit_transform(X)
# Fit data to grid_model
grid_model_result = grid_model.fit(rescaledX,y)
#  results
best_score, best_params = grid_model_result.best_score_,grid_model_result.best_params_
print("Best: %f using %s" % (best_score, best_params))

